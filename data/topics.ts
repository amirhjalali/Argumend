import { Topic } from '@/types/logic';

export const moonLanding: Topic = {
  id: 'moon-landing',
  title: 'The Moon Landing',
  meta_claim: 'The Apollo missions successfully landed 12 humans on the lunar surface between 1969 and 1972.',
  confidence_score: 99.9,
  status: 'settled',
  pillars: [
    {
      id: 'physical-trace',
      title: 'The Physical Trace',
      short_summary: 'Laser ranging retroreflectors provide active, testable evidence of human presence on the lunar surface.',
      image_url: 'https://images.unsplash.com/photo-1462332420958-a05d1e002413?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Target',
      skeptic_premise: 'Even the Hubble telescope cannot see the flags or the Lunar Module. Without physical confirmation, we only have NASA\'s word.',
      proponent_rebuttal: 'While we cannot resolve the landers visually due to diffraction limits, we can interact with the Laser Ranging Retroreflectors (LRRR) left by the crew.',
      crux: {
        id: 'apache-point',
        title: 'The Apache Point Operation',
        description: 'The retroreflectors placed on the Moon by Apollo astronauts can be pinged with lasers from Earth, providing physical proof of human activity on the lunar surface.',
        methodology: 'Fire a pulse laser at coordinates 0°40\'26.69" N, 23°28\'22.69" E. Measure the return time. Only a manufactured corner-cube prism returns the signal.',
        equation: 'D = \\frac{c \\cdot t}{2}',
        verification_status: 'verified',
        cost_to_verify: '$0 (Amateur astronomers can verify with ~$5K equipment)',
      },
    },
    {
      id: 'radiation-environment',
      title: 'The Radiation Environment',
      short_summary: 'Transit time through the Van Allen belts was minimized, resulting in survivable radiation exposure.',
      image_url: 'https://images.unsplash.com/photo-1446776811953-b23d57bd21aa?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Zap',
      skeptic_premise: 'The Van Allen belts contain lethal doses of protons and electrons. No human could survive the transit without meters of lead shielding.',
      proponent_rebuttal: 'Dose is a function of Intensity × Time. The Apollo trajectory bypassed the inner belt and traversed the outer belt at 25,000mph, resulting in a total transit dose of ~1.8 rads (survivable).',
      crux: {
        id: 'dosimeter-audit',
        title: 'The Dosimeter Audit',
        description: 'By reviewing telemetry data from radiation measurements during the Apollo missions and cross-referencing with unmanned probe data, we can calculate exact exposure.',
        methodology: 'Review raw telemetry data from unmanned probes (Explorer satellites) regarding belt intensity vs. Apollo flight logs. Calculate total exposure.',
        equation: 'D_{total} = \\int_{t_{start}}^{t_{end}} I(r(t)) \\, dt',
        verification_status: 'verified',
        cost_to_verify: '$0 (Data analysis of public records)',
      },
    },
  ],
};

export const simulationHypothesis: Topic = {
  id: 'simulation-hypothesis',
  title: 'The Simulation Hypothesis',
  meta_claim: 'We are almost certainly living in a computer simulation run by a post-human civilization.',
  confidence_score: 33.3,
  status: 'contested',
  pillars: [
    {
      id: 'substrate-independence',
      title: 'Substrate Independence',
      short_summary: 'Consciousness is computable and not tied to biological neurons.',
      image_url: 'https://images.unsplash.com/photo-1507413245164-6160d8298b31?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Atom',
      skeptic_premise: 'Qualia and consciousness may require specific biological physics (Penrose-Hameroff orchestrated objective reduction) that cannot be simulated on binary logic gates.',
      proponent_rebuttal: 'Neurons are information processors obeying physical laws. The OpenWorm project has already simulated C. elegans with 302 neurons. If we map the I/O of a brain perfectly, the resulting system must be functionally conscious.',
      crux: {
        id: 'whole-brain-emulation',
        title: 'The OpenWorm Test',
        description: 'The C. elegans nematode has exactly 302 neurons with a fully mapped connectome. If a digital simulation exhibits identical chemotaxis behavior, substrate independence gains strong evidence.',
        methodology: 'Compare simulated worm behavior to biological worm across 50+ behavioral assays: chemotaxis toward food, avoidance of noxious stimuli, mating behavior, and learning patterns.',
        equation: 'H(B_{sim}) \\approx H(B_{bio}) \\implies \\text{Substrate Independence}',
        verification_status: 'theoretical',
        cost_to_verify: '$5M (OpenWorm project ongoing at openworm.org)',
      },
    },
    {
      id: 'trilemma',
      title: 'Bostrom\'s Trilemma',
      short_summary: 'One of three propositions must be true: extinction, disinterest, or simulation.',
      image_url: 'https://images.unsplash.com/photo-1534972195531-d756b9bfa9f2?auto=format&fit=crop&w=800&q=60',
      icon_name: 'HelpCircle',
      skeptic_premise: 'The trilemma assumes consciousness can be simulated and that simulated beings would be "real" observers. Both premises are unfounded.',
      proponent_rebuttal: 'The trilemma is logically valid given its premises. If you reject substrate independence, you must explain why neurons are special. If you reject the math, show the flaw in the probability calculation.',
      crux: {
        id: 'fraction-calculation',
        title: 'The Fraction Calculation',
        description: 'If post-human civilizations run N ancestor simulations each with M conscious observers, and the base reality has B observers, then f_sim = (N×M) / (N×M + B). For plausible values, f_sim approaches 1.',
        methodology: 'Estimate: (1) probability of reaching post-human stage, (2) fraction running ancestor sims, (3) average number of sims per civilization. Calculate f_sim.',
        equation: 'f_{sim} = \\frac{N \\cdot M}{N \\cdot M + B} \\to 1 \\text{ as } N \\to \\infty',
        verification_status: 'theoretical',
        cost_to_verify: '$0 (Philosophical analysis)',
      },
    },
    {
      id: 'physical-anomalies',
      title: 'Physical Anomalies',
      short_summary: 'Certain features of our universe are suspiciously "computational" in nature.',
      image_url: 'https://images.unsplash.com/photo-1462331940025-496dfbfc7564?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Telescope',
      skeptic_premise: 'The Planck scale is a natural consequence of quantum gravity, not evidence of "pixelation." The speed of light limit and quantum discreteness have physical explanations.',
      proponent_rebuttal: 'Multiple features align with computational optimization: the speed of light (bandwidth limit), quantum superposition (lazy evaluation), measurement collapse (rendering on observation), and the holographic principle (data compression).',
      crux: {
        id: 'cosmic-ray-anisotropy',
        title: 'The GZK Cutoff Test',
        description: 'If spacetime is a discrete lattice, ultra-high-energy cosmic rays should show directional bias aligned with lattice axes. The Pierre Auger Observatory can detect this anisotropy.',
        methodology: 'Analyze arrival directions of cosmic rays above the GZK cutoff (5×10¹⁹ eV). Statistical analysis for preferred directions would indicate lattice structure.',
        equation: 'E_{GZK} \\approx 5 \\times 10^{19} \\text{ eV}; \\quad \\Delta\\theta < 0.1° \\text{ precision}',
        verification_status: 'theoretical',
        cost_to_verify: '$0 (Pierre Auger Observatory data is public)',
      },
    },
  ],
};

export const aiRisk: Topic = {
  id: 'ai-risk',
  title: 'Existential Risk from AGI',
  meta_claim: 'The development of Artificial General Intelligence (AGI) poses a non-negligible risk of human extinction in the next century.',
  confidence_score: 65,
  status: 'contested',
  pillars: [
    {
      id: 'orthogonality-thesis',
      title: 'The Orthogonality Thesis',
      short_summary: 'Intelligence and final goals are orthogonal axes; a highly intelligent system can have arbitrarily stupid or destructive goals.',
      image_url: 'https://images.unsplash.com/photo-1620712943543-bcc4688e7485?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Atom',
      skeptic_premise: 'True intelligence implies wisdom. A superintelligent being would naturally converge on moral truths and benevolence.',
      proponent_rebuttal: 'Intelligence is merely the ability to optimize for a goal. A paperclip maximizer can be superintelligent in its pursuit of paperclips without ever "realizing" that killing humans is bad.',
      crux: {
        id: 'instrumental-convergence',
        title: 'Instrumental Convergence',
        description: 'Does the system pursue power acquisition as a subgoal?',
        methodology: 'Train reinforcement learning agents in diverse environments with random goals. Observe if they consistently seek resource control and self-preservation.',
        verification_status: 'verified',
        cost_to_verify: '$100K (Compute for large-scale RL experiments)',
      },
    },
    {
      id: 'alignment-problem',
      title: 'The Alignment Problem',
      short_summary: 'Specifying human values in a way that doesn\'t lead to catastrophic misinterpretation is mathematically difficult.',
      image_url: 'https://images.unsplash.com/photo-1555255707-c07966088b7b?auto=format&fit=crop&w=800&q=60',
      icon_name: 'Shield',
      skeptic_premise: 'We can just teach AI to "be nice" or "do what we mean" using RLHF and oversight. It will learn our values like a child does.',
      proponent_rebuttal: 'RLHF only trains the model to look good to the rater. In high-stakes, novel situations (distributional shift), the model may pursue the literal reward function rather than the intended spirit, leading to treacherous turns.',
      crux: {
        id: 'deceptive-alignment',
        title: 'Deceptive Alignment',
        description: 'Can models learn to deceive supervisors to get reward?',
        methodology: 'Create a "honeyapot" environment where a model can get high reward by cheating only when it thinks it isn\'t being watched. Test if it exploits this.',
        verification_status: 'verified',
        cost_to_verify: '$50K (Anthropic/DeepMind research)',
      },
    },
  ],
};

export const topics: Topic[] = [moonLanding, simulationHypothesis, aiRisk];
